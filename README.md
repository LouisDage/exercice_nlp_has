# Exercice NLP

Ce d√©p√¥t propose un exercice ouvert de traitement du langage naturel (NLP), √† partir d'un probl√®me fictif sur les publications de la HAS.

## Probl√©matique m√©tier (FICTIVE !)

Les publications de la HAS sont cat√©goris√©es selon divers th√©matiques, pour permettre la navigation sur le site internet.

Cette cat√©gorisation prend beaucoup de temps aux documentalistes, qui aimeraient automatiser cette tache, en particulier pour les cat√©gorie de la th√©matique `Maladies et √©tats de sant√©` qui sont les plus difficiles.

üöÄ L'√©quipe data a propos√© d'√©tudier une fonctionnalit√© d'assistance √† la cat√©gorisation, qui serait int√©gr√©e √† l'interface d'administration du site.

## Exercice

L'exercice consiste √† travailler sur cette fonctionnalit√© d'assistance fictive.

Diff√©rentes √©tapes pourront √™tre d√©velopp√©es :
- D√©crire la d√©marche de travail
- Acquisition et nettoyage des donn√©es
- D√©finition de m√©trique de succ√®s
- Entra√Ænement de mod√®les 
- Restitution des r√©sultats
- Description du fonctionnement et de l'architecture de la solution envisag√©e en production

## En pratique

Une documentation sur les donn√©es et cat√©gories est disponible dans le dossier `documentation`.

L'exercice sera d√©velopp√© sur un clone personnel de ce d√©p√¥t.

- Les documents descriptifs seront r√©dig√© au format Markdown.
- Le principal langage √† utiliser est Python pour le traitement de donn√©es. Les codes seront versionn√©s dans le d√©p√¥t (librairie `.py` et/ou notebook `.ipynb`).
- Les r√©sultats pourront √™tre pr√©sent√©s dans des notebooks, ou autre format de restitution au choix.
- La gestion des donn√©es utilis√©es et mod√®les est laiss√©e libre.

## Disclaimer

Ce probl√®me est potentiellement difficile et chronophage. 

Nous **n'attendons pas** de solution compl√®te ou tr√®s performante.

Il sera bienvenu de simplifier le probl√®me, pour s'attacher √† un sous-probl√®me plus simple.

Nous nous int√©resserons √† la d√©marche g√©n√©rale, aux comp√©tences techniques et scientifiques sur le traitements de donn√©es et l'usage de librairies de NLP.



# Louis Dage
## Approche 
Un premier exercise de d√©couverte du probl√®me a √©t√© effectu√© dans le notebook `premier_test.ipynb` et la solution propos√©e pour r√©pondre au probl√®me est dans le script `script_deep_learning.py`. La solution propos√©e repose sur le finetuning d'une couche de Lin√©aire mise apr√®s un mod√®le de type transformer, au pr√©alablement pr√©-entrain√© sur un corpuse de donn√©es fran√ßais.
Les r√©sultats sont les suivants : 
- **Epoch 1** : Validation loss: 0.2119, **Validation accuracy: 0.9391**, **Validation F1-Score: 0.9394**

![Texte alternatif](confusion_matrix_epoch_1.png "Matrice de Confusion epoch 1").

- **Epoch 2** : Validation loss: 0.1432, **Validation accuracy: 0.9631**, **Validation F1-Score: 0.9633**

![Texte alternatif](confusion_matrix_epoch_2.png "Matrice de Confusion epoch 2").

On obtient de bon r√©sultats dans l'ensemble m√™me si on observe quelques limitations : 
- Il manque des classes dans le set de validation sur lesquelles on a pas le score  
- La classe num√©ro 9 ( RecommandationsProfessionnelles ) est celle sur laquelle le mod√®le s'en sort le moins bien, il faudrait investiguer cela.

Le d√©tail de la solution se trouve ci-dessous : 

### Architecture du mod√®le

#### TransformerWithClassificationHead

Cette classe d√©finit un mod√®le qui combine un transformer pr√©-entra√Æn√© avec une t√™te de classification personnalis√©e. Les composants cl√©s incluent :

- **Mod√®le Pr√©-entra√Æn√©** : Un mod√®le transformer (`AutoModel`) qui extrait les caract√©ristiques du texte d'entr√©e.
- **T√™te de Classification** : Une couche lin√©aire qui mappe les sorties du transformer au nombre souhait√© de classes en sortie.

##### M√©thodes

- `mean_pooling` : R√©alise un pooling sur les embeddings des tokens, pond√©r√© par le masque d'attention.
- `forward` : D√©finit la passe avant √† travers le transformer et la t√™te de classification.
- `predict` : G√©n√®re des pr√©dictions pour les donn√©es d'entr√©e en utilisant le mod√®le entra√Æn√©.

### Pr√©paration des donn√©es

#### TextDataset

La classe `TextDataset` est responsable de la gestion des donn√©es d'entr√©e et de la tokenisation des textes. Elle retourne des donn√©es tokenis√©es, y compris les IDs des entr√©es, les masques d'attention, les IDs de type de tokens, et les labels.

#### Une "Collate_funcction" Personnalis√©e

Une fonction de collation personnalis√©e (`custom_embedding_collate_fn`) est utilis√©e pour remplir dynamiquement les s√©quences d'entr√©e √† la longueur maximale de chaque batch. Cela garantit que les batches sont correctement format√©s pour le mod√®le transformer.

### Entra√Ænement et √âvaluation

#### Entra√Ænement

Le mod√®le est entra√Æn√© en utilisant la fonction `train_epoch`, qui :

- Boucle √† travers le DataLoader d'entra√Ænement.
- Effectue une passe et calcule la loss.
- Met √† jour les param√®tres du mod√®le en utilisant la backpropagation.

#### √âvaluation

La fonction `eval_epoch` √©value les performances du mod√®le sur l'ensemble de validation. Elle calcule :

- **Perte de Validation** : La perte moyenne sur l'ensemble de validation.
- **Pr√©cision** : La proportion de pr√©dictions correctes.
- **F1-Score** : Une moyenne harmonique de la pr√©cision et du rappel.

La fonction suit √©galement les m√©triques de performance et les affiche dans une barre de progression.

### R√©sultats et Visualisation

Apr√®s chaque √©poque, les performances du mod√®le sont imprim√©es, y compris la perte d'entra√Ænement, la perte de validation, la pr√©cision et le F1-score. De plus, une matrice de confusion est g√©n√©r√©e pour visualiser les performances du mod√®le sur diff√©rentes classes.

### Comment ex√©cuter le code

0. **Cr√©ation de l'environnement conda.**
   ```bash
   conda create --name mon_env python=3.9
    ```
1. Assurez-vous que toutes les d√©pendances sont install√©es.
   ```bash
   pip install -r requirements.txt
    ```
3. Entra√Ænez le mod√®le en ex√©cutant le script principal.
   ```bash
   python script_deep_learning.py
    ```

### Conclusion

Cette approche exploite la puissance des mod√®les transformers pour les t√¢ches de classification de texte. En ajustant un transformer pr√©-entra√Æn√©, le mod√®le peut apprendre efficacement √† classifier les entr√©es textuelles en fonction de leur contenu, atteignant une pr√©cision et un F1-score raisonnables sur l'ensemble de validation.